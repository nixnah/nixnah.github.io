<!doctype html><html lang=zh-cn><head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#"><meta charset=utf-8><meta name=generator content="Hugo 0.91.2"><meta name=theme-color content="#16171d"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=format-detection content="telephone=no, date=no, address=no, email=no"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><title>61.网络爬虫和相关工具 | Hanxin</title><link rel=stylesheet href=/css/meme.min.88c90dc75021618344ec926f4ed6ac307f30ba48911294816b16370a41e5f137.css><script src=/js/meme.min.f460a174bb100a60a7e275913695161f1e09aab1378fe99cfd30cde14da70888.js></script>
<link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&family=Noto+Serif+SC:wght@400;500;700&family=Source+Code+Pro:ital,wght@0,400;0,700;1,400;1,700&family=Satisfy&family=Klee+One:wght@400;600&family=Great+Vibes&display=swap" media=print onload="this.media='all'"><noscript><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&family=Noto+Serif+SC:wght@400;500;700&family=Source+Code+Pro:ital,wght@0,400;0,700;1,400;1,700&family=Satisfy&family=Klee+One:wght@400;600&family=Great+Vibes&display=swap"></noscript><meta name=author content="骆昊"><meta name=description content="网络爬虫和相关工具 网络爬虫的概念 网络爬虫（web crawler），以前经常称之为网络……"><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=mask-icon href=/icons/safari-pinned-tab.svg color=#2a6df4><link rel=apple-touch-icon sizes=180x180 href=/icons/apple-touch-icon.png><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-title content="Hanxin"><meta name=apple-mobile-web-app-status-bar-style content="black"><meta name=mobile-web-app-capable content="yes"><meta name=application-name content="Hanxin"><meta name=msapplication-starturl content="../../"><meta name=msapplication-TileColor content="#fff"><meta name=msapplication-TileImage content="../../icons/mstile-150x150.png"><link rel=manifest href=/manifest.json><link rel=canonical href=/python/61.%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%92%8C%E7%9B%B8%E5%85%B3%E5%B7%A5%E5%85%B7/><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebPage","datePublished":"2021-08-23T17:34:27+08:00","dateModified":"2022-01-16T09:24:35+00:00","url":"/python/61.%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%92%8C%E7%9B%B8%E5%85%B3%E5%B7%A5%E5%85%B7/","name":"61.网络爬虫和相关工具","description":"网络爬虫和相关工具 网络爬虫的概念 网络爬虫（web crawler），以前经常称之为网络……","image":"/icons/apple-touch-icon.png","license":"本文采用[「CC BY-NC-SA 4.0」](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)协议，转载请注明出处。","publisher":{"@type":"Organization","name":"Hanxin","logo":{"@type":"ImageObject","url":"/icons/apple-touch-icon.png"},"url":"/"},"mainEntityOfPage":{"@type":"WebSite","@id":"/"}}</script><meta name=twitter:card content="summary"><meta property="og:title" content="61.网络爬虫和相关工具"><meta property="og:description" content="网络爬虫和相关工具 网络爬虫的概念 网络爬虫（web crawler），以前经常称之为网络……"><meta property="og:url" content="/python/61.%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%92%8C%E7%9B%B8%E5%85%B3%E5%B7%A5%E5%85%B7/"><meta property="og:site_name" content="Hanxin"><meta property="og:locale" content="zh"><meta property="og:image" content="/icons/apple-touch-icon.png"><meta property="og:type" content="website"></head><body><div class=container><header class=header><div class=header-wrapper><div class="header-inner single"><div class=site-brand><a href=/ class=brand>Hanxin</a></div><nav class=nav><ul class=menu id=menu><li class=menu-item><a href=/life/><span class=menu-item-name>生活</span></a></li><li class=menu-item><a href=/tech/><span class=menu-item-name>技术</span></a></li><li class=menu-item><a href=/tags/><span class=menu-item-name>标签</span></a></li><li class=menu-item><a href=/about/><span class=menu-item-name>关于</span></a></li><li class=menu-item><a href=/blogroll/><span class=menu-item-name>友链</span></a></li><li class=menu-item><a href=/python/><span class=menu-item-name>Python-100天</span></a></li><li class=menu-item><a id=theme-switcher href=#><span class="icon theme-icon-light">🌞</span><span class="icon theme-icon-dark">🌙</span></a></li></ul></nav></div></div><input type=checkbox id=nav-toggle aria-hidden=true>
<label for=nav-toggle class=nav-toggle></label>
<label for=nav-toggle class=nav-curtain></label></header><main class="main single" id=main><div class=main-inner><article class="content post h-entry" data-align=justify data-type=python data-toc-num=true><h1 class="post-title p-name">61.网络爬虫和相关工具</h1><div class=post-meta><time datetime=2021-08-23T17:34:27+08:00 class="post-meta-item published dt-published"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M148 288h-40c-6.6.0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h48c26.5.0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3.0 6-2.7 6-6z"/></svg>&nbsp;2021.8.23</time>
<time datetime=2022-01-16T09:24:35+00:00 class="post-meta-item modified dt-updated"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M4e2 64h-48V12c0-6.627-5.373-12-12-12h-40c-6.627.0-12 5.373-12 12v52H160V12c0-6.627-5.373-12-12-12h-40c-6.627.0-12 5.373-12 12v52H48C21.49 64 0 85.49.0 112v352c0 26.51 21.49 48 48 48h352c26.51.0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm-6 4e2H54a6 6 0 01-6-6V160h352v298a6 6 0 01-6 6zm-52.849-200.65L198.842 404.519c-4.705 4.667-12.303 4.637-16.971-.068l-75.091-75.699c-4.667-4.705-4.637-12.303.068-16.971l22.719-22.536c4.705-4.667 12.303-4.637 16.97.069l44.104 44.461 111.072-110.181c4.705-4.667 12.303-4.637 16.971.068l22.536 22.718c4.667 4.705 4.636 12.303-.069 16.97z"/></svg>&nbsp;2022.1.16</time>
<span class="post-meta-item wordcount"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3.0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9.0l60.1 60.1c18.8 18.7 18.8 49.1.0 67.9zM284.2 99.8 21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3.0-17l-111-111c-4.8-4.7-12.4-4.7-17.1.0zM124.1 339.9c-5.5-5.5-5.5-14.3.0-19.8l154-154c5.5-5.5 14.3-5.5 19.8.0s5.5 14.3.0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8.0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;4223</span>
<span class="post-meta-item reading-time"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5.0-2e2-89.5-2e2-2e2S145.5 56 256 56s2e2 89.5 2e2 2e2-89.5 2e2-2e2 2e2zm61.8-104.4-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6.0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"/></svg>&nbsp;9&nbsp;分钟</span></div><div class="post-body e-content"><h2 id=网络爬虫和相关工具><a href=#网络爬虫和相关工具 class=anchor-link>#</a>网络爬虫和相关工具</h2><h3 id=网络爬虫的概念><a href=#网络爬虫的概念 class=anchor-link>#</a>网络爬虫的概念</h3><p>网络爬虫（web crawler），以前经常称之为网络蜘蛛（spider），是按照一定的规则自动浏览万维网并获取信息的机器人程序（或脚本），曾经被广泛的应用于互联网搜索引擎。使用过互联网和浏览器的人都知道，网页中除了供用户阅读的文字信息之外，还包含一些超链接。网络爬虫系统正是通过网页中的超链接信息不断获得网络上的其它页面。正因如此，网络数据采集的过程就像一个爬虫或者蜘蛛在网络上漫游，所以才被形象的称为网络爬虫或者网络蜘蛛。</p><h4 id=爬虫的应用领域><a href=#爬虫的应用领域 class=anchor-link>#</a>爬虫的应用领域</h4><p>在理想的状态下，所有ICP（Internet Content Provider）都应该为自己的网站提供API接口来共享它们允许其他程序获取的数据，在这种情况下爬虫就不是必需品，国内比较有名的电商平台（如淘宝、京东等）、社交平台（如腾讯微博等）等网站都提供了自己的Open API，但是这类Open API通常会对可以抓取的数据以及抓取数据的频率进行限制。对于大多数的公司而言，及时的获取行业相关数据是企业生存的重要环节之一，然而大部分企业在行业数据方面的匮乏是其与生俱来的短板，合理的利用爬虫来获取数据并从中提取出有商业价值的信息是至关重要的。当然爬虫还有很多重要的应用领域，下面列举了其中的一部分：</p><ol><li>搜索引擎</li><li>新闻聚合</li><li>社交应用</li><li>舆情监控</li><li>行业数据</li></ol><h3 id=合法性和背景调研><a href=#合法性和背景调研 class=anchor-link>#</a>合法性和背景调研</h3><h4 id=爬虫合法性探讨><a href=#爬虫合法性探讨 class=anchor-link>#</a>爬虫合法性探讨</h4><ol><li>网络爬虫领域目前还属于拓荒阶段，虽然互联网世界已经通过自己的游戏规则建立起一定的道德规范(Robots协议，全称是“网络爬虫排除标准”)，但法律部分还在建立和完善中，也就是说，现在这个领域暂时还是灰色地带。</li><li>“法不禁止即为许可”，如果爬虫就像浏览器一样获取的是前端显示的数据（网页上的公开信息）而不是网站后台的私密敏感信息，就不太担心法律法规的约束，因为目前大数据产业链的发展速度远远超过了法律的完善程度。</li><li>在爬取网站的时候，需要限制自己的爬虫遵守Robots协议，同时控制网络爬虫程序的抓取数据的速度；在使用数据的时候，必须要尊重网站的知识产权（从Web 2.0时代开始，虽然Web上的数据很多都是由用户提供的，但是网站平台是投入了运营成本的，当用户在注册和发布内容时，平台通常就已经获得了对数据的所有权、使用权和分发权）。如果违反了这些规定，在打官司的时候败诉几率相当高。</li></ol><h4 id=robotstxt文件><a href=#robotstxt文件 class=anchor-link>#</a>Robots.txt文件</h4><p>大多数网站都会定义robots.txt文件，下面以淘宝的<a href=http://www.taobao.com/robots.txt target=_blank rel=noopener>robots.txt</a>文件为例，看看该网站对爬虫有哪些限制。</p><pre tabindex=0><code>User-agent:  Baiduspider
Allow:  /article
Allow:  /oshtml
Disallow:  /product/
Disallow:  /

User-Agent:  Googlebot
Allow:  /article
Allow:  /oshtml
Allow:  /product
Allow:  /spu
Allow:  /dianpu
Allow:  /oversea
Allow:  /list
Disallow:  /

User-agent:  Bingbot
Allow:  /article
Allow:  /oshtml
Allow:  /product
Allow:  /spu
Allow:  /dianpu
Allow:  /oversea
Allow:  /list
Disallow:  /

User-Agent:  360Spider
Allow:  /article
Allow:  /oshtml
Disallow:  /

User-Agent:  Yisouspider
Allow:  /article
Allow:  /oshtml
Disallow:  /

User-Agent:  Sogouspider
Allow:  /article
Allow:  /oshtml
Allow:  /product
Disallow:  /

User-Agent:  Yahoo!  Slurp
Allow:  /product
Allow:  /spu
Allow:  /dianpu
Allow:  /oversea
Allow:  /list
Disallow:  /

User-Agent:  *
Disallow:  /
</code></pre><p>注意上面robots.txt第一段的最后一行，通过设置“Disallow: /”禁止百度爬虫访问除了“Allow”规定页面外的其他所有页面。因此当你在百度搜索“淘宝”的时候，搜索结果下方会出现：“由于该网站的robots.txt文件存在限制指令（限制搜索引擎抓取），系统无法提供该页面的内容描述”。百度作为一个搜索引擎，至少在表面上遵守了淘宝网的robots.txt协议，所以用户不能从百度上搜索到淘宝内部的产品信息。</p><p><img src=/res/baidu-search-taobao.png alt></p><h3 id=相关工具介绍><a href=#相关工具介绍 class=anchor-link>#</a>相关工具介绍</h3><h4 id=http协议><a href=#http协议 class=anchor-link>#</a>HTTP协议</h4><p>在开始讲解爬虫之前，我们稍微对HTTP（超文本传输协议）做一些回顾，因为我们在网页上看到的内容通常是浏览器执行HTML语言得到的结果，而HTTP就是传输HTML数据的协议。HTTP和其他很多应用级协议一样是构建在TCP（传输控制协议）之上的，它利用了TCP提供的可靠的传输服务实现了Web应用中的数据交换。按照维基百科上的介绍，设计HTTP最初的目的是为了提供一种发布和接收<a href=https://zh.wikipedia.org/wiki/HTML target=_blank rel=noopener>HTML</a>页面的方法，也就是说这个协议是浏览器和Web服务器之间传输的数据的载体。关于这个协议的详细信息以及目前的发展状况，大家可以阅读阮一峰老师的<a href=http://www.ruanyifeng.com/blog/2016/08/http.html target=_blank rel=noopener>《HTTP 协议入门》</a>、<a href=http://www.ruanyifeng.com/blog/2012/05/internet_protocol_suite_part_i.html target=_blank rel=noopener>《互联网协议入门》</a>系列以及<a href=http://www.ruanyifeng.com/blog/2014/09/illustration-ssl.html target=_blank rel=noopener>《图解HTTPS协议》</a>进行了解，下图是我在四川省网络通信技术重点实验室工作期间用开源协议分析工具Ethereal（抓包工具WireShark的前身）截取的访问百度首页时的HTTP请求和响应的报文（协议数据），由于Ethereal截取的是经过网络适配器的数据，因此可以清晰的看到从物理链路层到应用层的协议数据。</p><p>HTTP请求（请求行+请求头+空行+[消息体]）：</p><p><img src=/res/http-request.png alt></p><p>HTTP响应（响应行+响应头+空行+消息体）：</p><p><img src=/res/http-response.png alt></p><blockquote><p>说明：但愿这两张如同泛黄照片般的截图帮助你大概的了解到HTTP是一个怎样的协议。</p></blockquote><h4 id=相关工具><a href=#相关工具 class=anchor-link>#</a>相关工具</h4><ol><li><p>Chrome Developer Tools：谷歌浏览器内置的开发者工具。</p><p><img src=/res/chrome-developer-tools.png alt></p></li><li><p>Postman：功能强大的网页调试与RESTful请求工具。</p><p><img src=/res/postman.png alt></p></li><li><p>HTTPie：命令行HTTP客户端。</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Bash data-lang=Bash>pip3 install httpie
</code></pre></td></tr></table></div></div></div><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Bash data-lang=Bash>http --header http://www.scu.edu.cn
HTTP/1.1 <span class=m>200</span> OK
Accept-Ranges: bytes
Cache-Control: private, max-age<span class=o>=</span><span class=m>600</span>
Connection: Keep-Alive
Content-Encoding: gzip
Content-Language: zh-CN
Content-Length: <span class=m>14403</span>
Content-Type: text/html
Date: Sun, <span class=m>27</span> May <span class=m>2018</span> 15:38:25 GMT
ETag: <span class=s2>&#34;e6ec-56d3032d70a32-gzip&#34;</span>
Expires: Sun, <span class=m>27</span> May <span class=m>2018</span> 15:48:25 GMT
Keep-Alive: <span class=nv>timeout</span><span class=o>=</span>5, <span class=nv>max</span><span class=o>=</span><span class=m>100</span>
Last-Modified: Sun, <span class=m>27</span> May <span class=m>2018</span> 13:44:22 GMT
Server: VWebServer
Vary: User-Agent,Accept-Encoding
X-Frame-Options: SAMEORIGIN
</code></pre></td></tr></table></div></div></div></li><li><p><code>builtwith</code>库：识别网站所用技术的工具。</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Bash data-lang=Bash>pip3 install builtwith
</code></pre></td></tr></table></div></div></div><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=o>&gt;&gt;&gt;</span> <span class=kn>import</span> <span class=nn>builtwith</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>builtwith</span><span class=o>.</span><span class=n>parse</span><span class=p>(</span><span class=s1>&#39;http://www.bootcss.com/&#39;</span><span class=p>)</span>
<span class=p>{</span><span class=s1>&#39;web-servers&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Nginx&#39;</span><span class=p>],</span> <span class=s1>&#39;font-scripts&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Font Awesome&#39;</span><span class=p>],</span> <span class=s1>&#39;javascript-frameworks&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Lo-dash&#39;</span><span class=p>,</span> <span class=s1>&#39;Underscore.js&#39;</span><span class=p>,</span> <span class=s1>&#39;Vue.js&#39;</span><span class=p>,</span> <span class=s1>&#39;Zepto&#39;</span><span class=p>,</span> <span class=s1>&#39;jQuery&#39;</span><span class=p>],</span> <span class=s1>&#39;web-frameworks&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Twitter Bootstrap&#39;</span><span class=p>]}</span>
<span class=o>&gt;&gt;&gt;</span>
<span class=o>&gt;&gt;&gt;</span> <span class=kn>import</span> <span class=nn>ssl</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>ssl</span><span class=o>.</span><span class=n>_create_default_https_context</span> <span class=o>=</span> <span class=n>ssl</span><span class=o>.</span><span class=n>_create_unverified_context</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>builtwith</span><span class=o>.</span><span class=n>parse</span><span class=p>(</span><span class=s1>&#39;https://www.jianshu.com/&#39;</span><span class=p>)</span>
<span class=p>{</span><span class=s1>&#39;web-servers&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Tengine&#39;</span><span class=p>],</span> <span class=s1>&#39;web-frameworks&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Twitter Bootstrap&#39;</span><span class=p>,</span> <span class=s1>&#39;Ruby on Rails&#39;</span><span class=p>],</span> <span class=s1>&#39;programming-languages&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Ruby&#39;</span><span class=p>]}</span>
</code></pre></td></tr></table></div></div></div></li><li><p><code>python-whois</code>库：查询网站所有者的工具。</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Bash data-lang=Bash>pip3 install python-whois
</code></pre></td></tr></table></div></div></div><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=o>&gt;&gt;&gt;</span> <span class=kn>import</span> <span class=nn>whois</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>whois</span><span class=o>.</span><span class=n>whois</span><span class=p>(</span><span class=s1>&#39;baidu.com&#39;</span><span class=p>)</span>
<span class=p>{</span><span class=s1>&#39;domain_name&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;BAIDU.COM&#39;</span><span class=p>,</span> <span class=s1>&#39;baidu.com&#39;</span><span class=p>],</span> <span class=s1>&#39;registrar&#39;</span><span class=p>:</span> <span class=s1>&#39;MarkMonitor, Inc.&#39;</span><span class=p>,</span> <span class=s1>&#39;whois_server&#39;</span><span class=p>:</span> <span class=s1>&#39;whois.markmonitor.com&#39;</span><span class=p>,</span> <span class=s1>&#39;referral_url&#39;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;updated_date&#39;</span><span class=p>:</span> <span class=p>[</span><span class=n>datetime</span><span class=o>.</span><span class=n>datetime</span><span class=p>(</span><span class=mi>2017</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>28</span><span class=p>),</span> <span class=n>datetime</span><span class=o>.</span><span class=n>datetime</span><span class=p>(</span><span class=mi>2017</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>28</span><span class=p>)],</span> <span class=s1>&#39;creation_date&#39;</span><span class=p>:</span> <span class=p>[</span><span class=n>datetime</span><span class=o>.</span><span class=n>datetime</span><span class=p>(</span><span class=mi>1999</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>17</span><span class=p>),</span> <span class=n>datetime</span><span class=o>.</span><span class=n>datetime</span><span class=p>(</span><span class=mi>1999</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>17</span><span class=p>)],</span> <span class=s1>&#39;expiration_date&#39;</span><span class=p>:</span> <span class=p>[</span><span class=n>datetime</span><span class=o>.</span><span class=n>datetime</span><span class=p>(</span><span class=mi>2026</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>17</span><span class=p>),</span> <span class=n>datetime</span><span class=o>.</span><span class=n>datetime</span><span class=p>(</span><span class=mi>2026</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>)],</span> <span class=s1>&#39;name_servers&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;DNS.BAIDU.COM&#39;</span><span class=p>,</span> <span class=s1>&#39;NS2.BAIDU.COM&#39;</span><span class=p>,</span> <span class=s1>&#39;NS3.BAIDU.COM&#39;</span><span class=p>,</span> <span class=s1>&#39;NS4.BAIDU.COM&#39;</span><span class=p>,</span> <span class=s1>&#39;NS7.BAIDU.COM&#39;</span><span class=p>,</span> <span class=s1>&#39;dns.baidu.com&#39;</span><span class=p>,</span> <span class=s1>&#39;ns4.baidu.com&#39;</span><span class=p>,</span> <span class=s1>&#39;ns3.baidu.com&#39;</span><span class=p>,</span> <span class=s1>&#39;ns7.baidu.com&#39;</span><span class=p>,</span> <span class=s1>&#39;ns2.baidu.com&#39;</span><span class=p>],</span> <span class=s1>&#39;status&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;clientDeleteProhibited https://icann.org/epp#clientDeleteProhibited&#39;</span><span class=p>,</span> <span class=s1>&#39;clientTransferProhibited https://icann.org/epp#clientTransferProhibited&#39;</span><span class=p>,</span> <span class=s1>&#39;clientUpdateProhibited https://icann.org/epp#clientUpdateProhibited&#39;</span><span class=p>,</span> <span class=s1>&#39;serverDeleteProhibited https://icann.org/epp#serverDeleteProhibited&#39;</span><span class=p>,</span> <span class=s1>&#39;serverTransferProhibited https://icann.org/epp#serverTransferProhibited&#39;</span><span class=p>,</span> <span class=s1>&#39;serverUpdateProhibited https://icann.org/epp#serverUpdateProhibited&#39;</span><span class=p>,</span> <span class=s1>&#39;clientUpdateProhibited (https://www.icann.org/epp#clientUpdateProhibited)&#39;</span><span class=p>,</span> <span class=s1>&#39;clientTransferProhibited (https://www.icann.org/epp#clientTransferProhibited)&#39;</span><span class=p>,</span> <span class=s1>&#39;clientDeleteProhibited (https://www.icann.org/epp#clientDeleteProhibited)&#39;</span><span class=p>,</span> <span class=s1>&#39;serverUpdateProhibited (https://www.icann.org/epp#serverUpdateProhibited)&#39;</span><span class=p>,</span> <span class=s1>&#39;serverTransferProhibited (https://www.icann.org/epp#serverTransferProhibited)&#39;</span><span class=p>,</span> <span class=s1>&#39;serverDeleteProhibited (https://www.icann.org/epp#serverDeleteProhibited)&#39;</span><span class=p>],</span> <span class=s1>&#39;emails&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;abusecomplaints@markmonitor.com&#39;</span><span class=p>,</span> <span class=s1>&#39;whoisrelay@markmonitor.com&#39;</span><span class=p>],</span> <span class=s1>&#39;dnssec&#39;</span><span class=p>:</span> <span class=s1>&#39;unsigned&#39;</span><span class=p>,</span> <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;org&#39;</span><span class=p>:</span> <span class=s1>&#39;Beijing Baidu Netcom Science Technology Co., Ltd.&#39;</span><span class=p>,</span> <span class=s1>&#39;address&#39;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;city&#39;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;state&#39;</span><span class=p>:</span> <span class=s1>&#39;Beijing&#39;</span><span class=p>,</span> <span class=s1>&#39;zipcode&#39;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span> <span class=s1>&#39;country&#39;</span><span class=p>:</span> <span class=s1>&#39;CN&#39;</span><span class=p>}</span>
</code></pre></td></tr></table></div></div></div></li><li><p><code>robotparser</code>模块：解析<code>robots.txt</code>的工具。</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=o>&gt;&gt;&gt;</span> <span class=kn>from</span> <span class=nn>urllib</span> <span class=kn>import</span> <span class=n>robotparser</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>parser</span> <span class=o>=</span> <span class=n>robotparser</span><span class=o>.</span><span class=n>RobotFileParser</span><span class=p>()</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>parser</span><span class=o>.</span><span class=n>set_url</span><span class=p>(</span><span class=s1>&#39;https://www.taobao.com/robots.txt&#39;</span><span class=p>)</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>parser</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>parser</span><span class=o>.</span><span class=n>can_fetch</span><span class=p>(</span><span class=s1>&#39;Baiduspider&#39;</span><span class=p>,</span> <span class=s1>&#39;http://www.taobao.com/article&#39;</span><span class=p>)</span>
<span class=kc>True</span>
<span class=o>&gt;&gt;&gt;</span> <span class=n>parser</span><span class=o>.</span><span class=n>can_fetch</span><span class=p>(</span><span class=s1>&#39;Baiduspider&#39;</span><span class=p>,</span> <span class=s1>&#39;http://www.taobao.com/product&#39;</span><span class=p>)</span>
<span class=kc>False</span>
</code></pre></td></tr></table></div></div></div></li></ol><h3 id=一个简单的爬虫><a href=#一个简单的爬虫 class=anchor-link>#</a>一个简单的爬虫</h3><p>一个基本的爬虫通常分为数据采集（网页下载）、数据处理（网页解析）和数据存储（将有用的信息持久化）三个部分的内容，当然更为高级的爬虫在数据采集和处理时会使用并发编程或分布式技术，这就需要有调度器（安排线程或进程执行对应的任务）、后台管理程序（监控爬虫的工作状态以及检查数据抓取的结果）等的参与。</p><p><img src=/res/crawler-workflow.png alt></p><p>一般来说，爬虫的工作流程包括以下几个步骤：</p><ol><li>设定抓取目标（种子页面/起始页面）并获取网页。</li><li>当服务器无法访问时，按照指定的重试次数尝试重新下载页面。</li><li>在需要的时候设置用户代理或隐藏真实IP，否则可能无法访问页面。</li><li>对获取的页面进行必要的解码操作然后抓取出需要的信息。</li><li>在获取的页面中通过某种方式（如正则表达式）抽取出页面中的链接信息。</li><li>对链接进行进一步的处理（获取页面并重复上面的动作）。</li><li>将有用的信息进行持久化以备后续的处理。</li></ol><p>下面的例子给出了一个从“搜狐体育”上获取NBA新闻标题和链接的爬虫。</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=kn>import</span> <span class=nn>re</span>
<span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>deque</span>
<span class=kn>from</span> <span class=nn>urllib.parse</span> <span class=kn>import</span> <span class=n>urljoin</span>

<span class=kn>import</span> <span class=nn>requests</span>

<span class=n>LI_A_PATTERN</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;&lt;li class=&#34;item&#34;&gt;.*?&lt;/li&gt;&#39;</span><span class=p>)</span>
<span class=n>A_TEXT_PATTERN</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;&lt;a\s+[^&gt;]*?&gt;(.*?)&lt;/a&gt;&#39;</span><span class=p>)</span>
<span class=n>A_HREF_PATTERN</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;&lt;a\s+[^&gt;]*?href=&#34;(.*?)&#34;\s*[^&gt;]*?&gt;&#39;</span><span class=p>)</span>


<span class=k>def</span> <span class=nf>decode_page</span><span class=p>(</span><span class=n>page_bytes</span><span class=p>,</span> <span class=n>charsets</span><span class=p>):</span>
    <span class=s2>&#34;&#34;&#34;通过指定的字符集对页面进行解码&#34;&#34;&#34;</span>
    <span class=k>for</span> <span class=n>charset</span> <span class=ow>in</span> <span class=n>charsets</span><span class=p>:</span>
        <span class=k>try</span><span class=p>:</span>
            <span class=k>return</span> <span class=n>page_bytes</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>charset</span><span class=p>)</span>
        <span class=k>except</span> <span class=ne>UnicodeDecodeError</span><span class=p>:</span>
            <span class=k>pass</span>


<span class=k>def</span> <span class=nf>get_matched_parts</span><span class=p>(</span><span class=n>content_string</span><span class=p>,</span> <span class=n>pattern</span><span class=p>):</span>
    <span class=s2>&#34;&#34;&#34;从字符串中提取所有跟正则表达式匹配的内容&#34;&#34;&#34;</span>
    <span class=k>return</span> <span class=n>pattern</span><span class=o>.</span><span class=n>findall</span><span class=p>(</span><span class=n>content_string</span><span class=p>,</span> <span class=n>re</span><span class=o>.</span><span class=n>I</span><span class=p>)</span> \
        <span class=k>if</span> <span class=n>content_string</span> <span class=k>else</span> <span class=p>[]</span>


<span class=k>def</span> <span class=nf>get_matched_part</span><span class=p>(</span><span class=n>content_string</span><span class=p>,</span> <span class=n>pattern</span><span class=p>,</span> <span class=n>group_no</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span>
    <span class=s2>&#34;&#34;&#34;从字符串中提取跟正则表达式匹配的内容&#34;&#34;&#34;</span>
    <span class=n>match</span> <span class=o>=</span> <span class=n>pattern</span><span class=o>.</span><span class=n>search</span><span class=p>(</span><span class=n>content_string</span><span class=p>)</span>
    <span class=k>if</span> <span class=n>match</span><span class=p>:</span>
        <span class=k>return</span> <span class=n>match</span><span class=o>.</span><span class=n>group</span><span class=p>(</span><span class=n>group_no</span><span class=p>)</span>


<span class=k>def</span> <span class=nf>get_page_html</span><span class=p>(</span><span class=n>seed_url</span><span class=p>,</span> <span class=o>*</span><span class=p>,</span> <span class=n>charsets</span><span class=o>=</span><span class=p>(</span><span class=s1>&#39;utf-8&#39;</span><span class=p>,</span> <span class=p>)):</span>
    <span class=s2>&#34;&#34;&#34;获取页面的HTML代码&#34;&#34;&#34;</span>
    <span class=n>resp</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>seed_url</span><span class=p>)</span>
    <span class=k>if</span> <span class=n>resp</span><span class=o>.</span><span class=n>status_code</span> <span class=o>==</span> <span class=mi>200</span><span class=p>:</span>
        <span class=k>return</span> <span class=n>decode_page</span><span class=p>(</span><span class=n>resp</span><span class=o>.</span><span class=n>content</span><span class=p>,</span> <span class=n>charsets</span><span class=p>)</span>


<span class=k>def</span> <span class=nf>repair_incorrect_href</span><span class=p>(</span><span class=n>current_url</span><span class=p>,</span> <span class=n>href</span><span class=p>):</span>
    <span class=s2>&#34;&#34;&#34;修正获取的href属性&#34;&#34;&#34;</span>
    <span class=k>if</span> <span class=n>href</span><span class=o>.</span><span class=n>startswith</span><span class=p>(</span><span class=s1>&#39;//&#39;</span><span class=p>):</span>
        <span class=n>href</span> <span class=o>=</span> <span class=n>urljoin</span><span class=p>(</span><span class=s1>&#39;http://&#39;</span><span class=p>,</span> <span class=n>href</span><span class=p>)</span>
    <span class=k>elif</span> <span class=n>href</span><span class=o>.</span><span class=n>startswith</span><span class=p>(</span><span class=s1>&#39;/&#39;</span><span class=p>):</span>
        <span class=n>href</span> <span class=o>=</span> <span class=n>urljoin</span><span class=p>(</span><span class=n>current_url</span><span class=p>,</span> <span class=n>href</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>href</span> <span class=k>if</span> <span class=n>href</span><span class=o>.</span><span class=n>startswith</span><span class=p>(</span><span class=s1>&#39;http&#39;</span><span class=p>)</span> <span class=k>else</span> <span class=s1>&#39;&#39;</span>


<span class=k>def</span> <span class=nf>start_crawl</span><span class=p>(</span><span class=n>seed_url</span><span class=p>,</span> <span class=n>pattern</span><span class=p>,</span> <span class=o>*</span><span class=p>,</span> <span class=n>max_depth</span><span class=o>=-</span><span class=mi>1</span><span class=p>):</span>
    <span class=s2>&#34;&#34;&#34;开始爬取数据&#34;&#34;&#34;</span>
    <span class=n>new_urls</span><span class=p>,</span> <span class=n>visited_urls</span> <span class=o>=</span> <span class=n>deque</span><span class=p>(),</span> <span class=nb>set</span><span class=p>()</span>
    <span class=n>new_urls</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=n>seed_url</span><span class=p>,</span> <span class=mi>0</span><span class=p>))</span>
    <span class=k>while</span> <span class=n>new_urls</span><span class=p>:</span>
        <span class=n>current_url</span><span class=p>,</span> <span class=n>depth</span> <span class=o>=</span> <span class=n>new_urls</span><span class=o>.</span><span class=n>popleft</span><span class=p>()</span>
        <span class=k>if</span> <span class=n>depth</span> <span class=o>!=</span> <span class=n>max_depth</span><span class=p>:</span>
            <span class=n>page_html</span> <span class=o>=</span> <span class=n>get_page_html</span><span class=p>(</span><span class=n>current_url</span><span class=p>,</span> <span class=n>charsets</span><span class=o>=</span><span class=p>(</span><span class=s1>&#39;utf-8&#39;</span><span class=p>,</span> <span class=s1>&#39;gbk&#39;</span><span class=p>))</span>
            <span class=n>contents</span> <span class=o>=</span> <span class=n>get_matched_parts</span><span class=p>(</span><span class=n>page_html</span><span class=p>,</span> <span class=n>pattern</span><span class=p>)</span>
            <span class=k>for</span> <span class=n>content</span> <span class=ow>in</span> <span class=n>contents</span><span class=p>:</span>
                <span class=n>text</span> <span class=o>=</span> <span class=n>get_matched_part</span><span class=p>(</span><span class=n>content</span><span class=p>,</span> <span class=n>A_TEXT_PATTERN</span><span class=p>)</span>
                <span class=n>href</span> <span class=o>=</span> <span class=n>get_matched_part</span><span class=p>(</span><span class=n>content</span><span class=p>,</span> <span class=n>A_HREF_PATTERN</span><span class=p>)</span>
                <span class=k>if</span> <span class=n>href</span><span class=p>:</span>
                    <span class=n>href</span> <span class=o>=</span> <span class=n>repair_incorrect_href</span><span class=p>(</span><span class=n>href</span><span class=p>)</span>
                <span class=nb>print</span><span class=p>(</span><span class=n>text</span><span class=p>,</span> <span class=n>href</span><span class=p>)</span>
                <span class=k>if</span> <span class=n>href</span> <span class=ow>and</span> <span class=n>href</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>visited_urls</span><span class=p>:</span>
                    <span class=n>new_urls</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=n>href</span><span class=p>,</span> <span class=n>depth</span> <span class=o>+</span> <span class=mi>1</span><span class=p>))</span>


<span class=k>def</span> <span class=nf>main</span><span class=p>():</span>
    <span class=s2>&#34;&#34;&#34;主函数&#34;&#34;&#34;</span>
    <span class=n>start_crawl</span><span class=p>(</span>
        <span class=n>seed_url</span><span class=o>=</span><span class=s1>&#39;http://sports.sohu.com/nba_a.shtml&#39;</span><span class=p>,</span>
        <span class=n>pattern</span><span class=o>=</span><span class=n>LI_A_PATTERN</span><span class=p>,</span>
        <span class=n>max_depth</span><span class=o>=</span><span class=mi>2</span>
    <span class=p>)</span>


<span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
    <span class=n>main</span><span class=p>()</span>
</code></pre></td></tr></table></div></div></div><h3 id=爬虫注意事项><a href=#爬虫注意事项 class=anchor-link>#</a>爬虫注意事项</h3><p>通过上面的例子，我们对爬虫已经有了一个感性的认识，在编写爬虫时有以下一些注意事项：</p><ol><li><p>上面的代码使用了<code>requests</code>三方库来获取网络资源，这是一个非常优质的三方库，关于它的用法可以参考它的<a href=https://requests.readthedocs.io/zh_CN/latest/ target=_blank rel=noopener>官方文档</a>。</p></li><li><p>上面的代码中使用了双端队列（<code>deque</code>）来保存待爬取的URL。双端队列相当于是使用链式存储结构的<code>list</code>，在双端队列的头尾添加和删除元素性能都比较好，刚好可以用来构造一个FIFO（先进先出）的队列结构。</p></li><li><p>处理相对路径。有的时候我们从页面中获取的链接不是一个完整的绝对链接而是一个相对链接，这种情况下需要将其与URL前缀进行拼接（<code>urllib.parse</code>中的<code>urljoin()</code>函数可以完成此项操作）。</p></li><li><p>设置代理服务。有些网站会限制访问的区域（例如美国的Netflix屏蔽了很多国家的访问），有些爬虫需要隐藏自己的身份，在这种情况下可以设置使用代理服务器，代理服务器有免费的服务器和付费的商业服务器，但后者稳定性和可用性都更好，强烈建议在商业项目中使用付费的商业代理服务器。如果使用<code>requests</code>三方库，可以在请求方法中添加<code>proxies</code>参数来指定代理服务器；如果使用标准库，可以通过修改<code>urllib.request</code>中的<code>ProxyHandler</code>来为请求设置代理服务器。</p></li><li><p>限制下载速度。如果我们的爬虫获取网页的速度过快，可能就会面临被封禁或者产生“损害动产”的风险（这个可能会导致吃官司且败诉），可以在两次获取页面数据之间添加延时从而对爬虫进行限速。</p></li><li><p>避免爬虫陷阱。有些网站会动态生成页面内容，这会导致产生无限多的页面（例如在线万年历通常会有无穷无尽的链接）。可以通过记录到达当前页面经过了多少个链接（链接深度）来解决该问题，当达到事先设定的最大深度时，爬虫就不再像队列中添加该网页中的链接了。</p></li><li><p>避开蜜罐链接。网站上的有些链接是浏览器中不可见的，这种链接通常是故意诱使爬虫去访问的蜜罐，一旦访问了这些链接，服务器就会判定请求是来自于爬虫的，这样可能会导致被服务器封禁IP地址。如何避开这些蜜罐链接我们在后面为大家进行讲解。</p></li><li><p>SSL相关问题。如果使用标准库的<code>urlopen</code>打开一个HTTPS链接时会验证一次SSL证书，如果不做出处理会产生错误提示“SSL: CERTIFICATE_VERIFY_FAILED”，可以通过以下两种方式加以解决：</p><ul><li><p>使用未经验证的上下文</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=kn>import</span> <span class=nn>ssl</span>

<span class=n>request</span> <span class=o>=</span> <span class=n>urllib</span><span class=o>.</span><span class=n>request</span><span class=o>.</span><span class=n>Request</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=s1>&#39;...&#39;</span><span class=p>,</span> <span class=n>headers</span><span class=o>=</span><span class=p>{</span><span class=o>...</span><span class=p>})</span> 
<span class=n>context</span> <span class=o>=</span> <span class=n>ssl</span><span class=o>.</span><span class=n>_create_unverified_context</span><span class=p>()</span>
<span class=n>web_page</span> <span class=o>=</span> <span class=n>urllib</span><span class=o>.</span><span class=n>request</span><span class=o>.</span><span class=n>urlopen</span><span class=p>(</span><span class=n>request</span><span class=p>,</span> <span class=n>context</span><span class=o>=</span><span class=n>context</span><span class=p>)</span>
</code></pre></td></tr></table></div></div></div></li><li><p>设置全局性取消证书验证</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=kn>import</span> <span class=nn>ssl</span>

<span class=n>ssl</span><span class=o>.</span><span class=n>_create_default_https_context</span> <span class=o>=</span> <span class=n>ssl</span><span class=o>.</span><span class=n>_create_unverified_context</span>
</code></pre></td></tr></table></div></div></div></li></ul></li></ol></div><ul class=post-copyright><li class="copyright-item author"><span class=copyright-item-text>作者</span>：<span class="p-author h-card">骆昊</span></li><li class="copyright-item link"><span class=copyright-item-text>链接</span>：<a href=https://github.com/jackfrued/Python-100-Days target=_blank rel=noopener>https://github.com/jackfrued/Python-100-Days</a></li><li class="copyright-item license"><span class=copyright-item-text>许可</span>：本文采用<a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh target=_blank rel=noopener>「CC BY-NC-SA 4.0」</a>协议，转载请注明出处。</li></ul></article><div class=related-posts><h2 class=related-title>相关文章：<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon related-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm144 276c0 6.6-5.4 12-12 12h-92v92c0 6.6-5.4 12-12 12h-56c-6.6.0-12-5.4-12-12v-92h-92c-6.6.0-12-5.4-12-12v-56c0-6.6 5.4-12 12-12h92v-92c0-6.6 5.4-12 12-12h56c6.6.0 12 5.4 12 12v92h92c6.6.0 12 5.4 12 12v56z"/></svg></h2><ul class=related-list><li class=related-item><a href=/python/01.%E5%88%9D%E8%AF%86python/ class=related-link>01.初识Python</a></li><li class=related-item><a href=/python/02.%E8%AF%AD%E8%A8%80%E5%85%83%E7%B4%A0/ class=related-link>02.语言元素</a></li><li class=related-item><a href=/python/03.%E5%88%86%E6%94%AF%E7%BB%93%E6%9E%84/ class=related-link>03.分支结构</a></li><li class=related-item><a href=/python/04.%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84/ class=related-link>04.循环结构</a></li><li class=related-item><a href=/python/05.%E6%9E%84%E9%80%A0%E7%A8%8B%E5%BA%8F%E9%80%BB%E8%BE%91/ class=related-link>05.构造程序逻辑</a></li></ul></div><div class=post-tags><a href=/tags/python/ rel=tag class=post-tags-link><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49.0 48 0h204.118a48 48 0 0133.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137.0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882.0L14.059 286.059A48 48 0 010 252.118zM112 64c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>python</a></div></div></main><div id=back-to-top class=back-to-top><a href=#><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon arrow-up"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6.0-33.9L207 39c9.4-9.4 24.6-9.4 33.9.0l194.3 194.3c9.4 9.4 9.4 24.6.0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3.0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg></a></div><footer id=footer class=footer><div class=footer-inner><div class=site-info>©&nbsp;2021–2022&nbsp;<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon footer-icon"><path d="M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3.0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z"/></svg>&nbsp;hanxin</div><script src=https://sdk.jinrishici.com/v2/browser/jinrishici.js></script>
<text class=poem_sentence></text>
<text class=poem_info></text>
<script type=text/javascript>jinrishici.load(function(a){var b=document.querySelector(".poem_sentence"),c=document.querySelector(".poem_info");b.innerHTML=a.data.content,c.innerHTML='——'+a.data.origin.author})</script></div></footer></div><script src=https://cdn.jsdelivr.net/npm/medium-zoom@latest/dist/medium-zoom.min.js></script>
<script>mediumZoom(document.querySelectorAll('div.post-body img'),{background:'hsla(var(--color-bg-h), var(--color-bg-s), var(--color-bg-l), 0.95)'})</script><script src=https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js type=module defer></script></body></html>